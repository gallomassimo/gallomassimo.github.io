@inproceedings{alessandria2009p2p,
  title={P2P-TV systems under adverse network conditions: a measurement study},
  author={A., Eugenio and M., Gallo and E., Leonardi and M., Mellia and M., Meo},
  booktitle={IEEE INFOCOM 2009},
  pages={100--108},
  year={2009},
  organization={IEEE},
  series={INFOCOM 09}
}

@inproceedings{muscariello2011bandwidth,
  title={Bandwidth and storage sharing performance in information centric networking},
  author={L., Muscariello and G., Carofiglio and M., Gallo},
  booktitle={Proceedings of the ACM SIGCOMM workshop on Information-centric networking},
  pages={26--31},
  year={2011},
  series={SIGCOMM-WS 11}
}

@inproceedings{carofiglio2011modeling,
  title={Modeling data transfer in content-centric networking},
  author={G., Carofiglio and M., Gallo and L., Muscariello and D., Perino},
  booktitle={2011 23rd International Teletraffic Congress (ITC)},
  pages={111--118},
  year={2011},
  organization={IEEE},
  series={ITC 11}
}

@article{gallo2014performance,
  title={Performance evaluation of the random replacement policy for networks of caches},
  author={M., Gallo and B., Kauffmann and L., Muscariello and A., Simonian and C., Tanguy},
  journal={Performance Evaluation},
  volume={72},
  pages={16--36},
  year={2014},
  publisher={North-Holland},
  series={Performance 14}
}

@article{alessandria2011impact,
  title={Impact of adverse network conditions on P2P-TV systems: Experimental evidence},
  author={Alessandria, Eugenio and M., Gallo and E., Leonardi and M., Mellia and M., Meo},
  journal={Computer Networks},
  volume={55},
  number={9},
  pages={2035--2050},
  year={2011},
  publisher={Elsevier},
  series={COMNET 11}
}

@article{carofiglio2012joint,
  title={Joint hop-by-hop and receiver-driven interest control protocol for content-centric networks},
  author={G., Carofiglio and M., Gallo and L., Muscariello},
  journal={ACM SIGCOMM Computer Communication Review},
  volume={42},
  number={4},
  pages={491--496},
  year={2012},
  publisher={ACM},
  series={CCR 12}
}

@article{carofiglio2013evaluating,
  title={Evaluating per-application storage management in content-centric networks},
  author={G., Carofiglio and M., Gallo and L., Muscariello and D., Perino},
  journal={Computer communications},
  volume={36},
  number={7},
  pages={750--757},
  year={2013},
  publisher={Elsevier},
  series={COMCOM 13}
}

@inproceedings{carofiglio2013multipath,
  title={Multipath congestion control in content-centric networks},
  author={G., Carofiglio and M., Gallo and L., Muscariello and M., Papalini},
  booktitle={2013 IEEE conference on computer communications workshops (INFOCOM WKSHPS)},
  pages={363--368},
  year={2013},
  organization={IEEE},
  series={INFOCOM-WS 13}
}

@inproceedings{carofiglio2012icp,
  title={ICP: Design and evaluation of an interest control protocol for content-centric networking},
  author={G., Carofiglio and M., Gallo and L., Muscariello},
  booktitle={2012 Proceedings IEEE INFOCOM Workshops},
  pages={304--309},
  year={2012},
  abstract={Content-centric networking (CCN) brings a paradigm shift in the present Internet communication model by addressing named-data instead of host locations. With respect to TCP/IP, the transport model is connectionless with a unique endpoint at the receiver, driving a retrieval process natively point to multi-point. Another salient feature of CCN is the possibility to embed storage capabilities into the network, adding a new dimension to the transport problem. The focus of this work is on the design of a receiver-driven Interest control protocol for CCN, whose definition, to the best of our knowledge, still lacks in literature. ICP realizes a window-based Interest flow control, achieving full efficiency and fairness under proper parameters setting. In this paper, we provide an analytical characterization of average rate, expected data transfer delay and queue dynamics in steady state on a single and multi-bottleneck network topology. Our model accounts for the impact of on-path caches. Protocol performance is also assessed via packet-level simulations and design guidelines are drawn from previous analysis.},
  organization={IEEE},
  series={INFOCOM-WS 12}
}

@article{carofiglio2013performance,
  title={On the performance of bandwidth and storage sharing in information-centric networks},
  author={G., Carofiglio and M., Gallo and L., Muscariello},
  journal={Computer Networks},
  volume={57},
  number={17},
  pages={3743--3758},
  year={2013},
  publisher={Elsevier},
  series={COMNET 13}
}

@misc{muscariello2017technique_PATENT,
  title={Technique for communication in a communications network with routing by name},
  author={L., Muscariello and M., Gallo},
  year={2017},
  month=jul # "~18",
  note={US Patent 9,712,602},
  series={Patent 17}
}

@inproceedings{carofiglio2013optimal,
  title={Optimal Multipath Congestion Control and Request Forwarding in Information-Centric Networks},
  author={G., Carofiglio and M., Gallo and L., Muscariello and M., Papalini and S., Wang},
  booktitle={Network Protocols (ICNP), 2013 21st IEEE International Conference on},
  pages={1--10},
  year={2013},
  organization={IEEE},
  series={ICNP 13}
}

@phdthesis{gallo2012gestion,
  title={Gestion du trafic et des ressources dans les r{\'e}seaux centr{\'e}s sur le contenu: design et {\'e}valuation},
  author={M., Gallo},
  year={2012},
  school={Paris, ENST},
  series={PhD thesis}
}

@inproceedings{gallo2014nanet,
  title={NaNET: socket API and protocol stack for process-to-content network communication},
  author={M., Gallo and Gu, Lin and D., Perino and M., Varvello},
  booktitle={Proceedings of the 1st ACM Conference on Information-Centric Networking},
  pages={185--186},
  year={2014},
  series={ICN 14}
}

@inproceedings{perino2014high,
  title={A high speed information-centric network in a mobile backhaul setting},
  author={D., Perino and M., Gallo and R., Boislaigue and L., Linguaglossa and M., Varvello and G., Carofiglio and L., Muscariello and Ben Houidi, Zied},
  booktitle={Proceedings of the 1st ACM Conference on Information-Centric Networking},
  pages={199--200},
  year={2014},
  series={ICN 14}
}

@phdthesis{gallo2012traffic,
  title={Traffic and resource management in content-centric networks: design and evaluation},
  author={M., Gallo},
  year={2012},
  school={T{\'e}l{\'e}com ParisTech},
  series={PhD thesis}
}

@inproceedings{carofiglio2015scalable,
  title={Scalable mobile backhauling via information-centric networking},
  author={G., Carofiglio and M., Gallo and L., Muscariello and D., Perino},
  booktitle={The 21st IEEE International Workshop on Local and Metropolitan Area Networks},
  pages={1--6},
  year={2015},
  organization={IEEE},
  series={LANMAN 15}
}

@inproceedings{mansilha2015hierarchical,
  title={Hierarchical content stores in high-speed ICN routers: Emulation and prototype implementation},
  author={R., Mansilha and L., Saino and M.P., Barcellos and M., Gallo and E., Leonardi and D., Perino and D., Rossi},
  booktitle={Proceedings of the 2nd ACM Conference on Information-Centric Networking},
  pages={59--68},
  year={2015},
  series={ICN 15}
}

@inproceedings{carofiglio2015pending,
  title={Pending interest table sizing in named data networking},
  author={G., Carofiglio and M., Gallo and L., Muscariello and D., Perino},
  booktitle={Proceedings of the 2Nd ACM Conference on Information-Centric Networking},
  pages={49--58},
  year={2015},
  series={ICN 15}
}

@inproceedings{pianese2016orchestrating,
  title={Orchestrating 5G virtual network functions as a modular Programmable Data Plane},
  author={F., Pianese and M., Gallo and A., Conte and D., Perino},
  booktitle={Network Operations and Management Symposium},
  pages={1305--1308},
  year={2016},
  organization={IEEE/IFIP},
  series={NOMS 16}
}

@article{laufer2016climb,
  title={Climb: Enabling network function composition with click middleboxes},
  author={R., Laufer and M., Gallo and D., Perino and A., Nandugudi},
  journal={ACM SIGCOMM Computer Communication Review},
  volume={46},
  number={4},
  pages={17--22},
  year={2016},
  publisher={ACM},
  series={CCR 16}
}

@inproceedings{rodrigues2016enabling,
  title={Enabling transparent caching in LTE mobile backhaul networks with SDN},
  author={M., Rodrigues and G., D{\'a}n and M., Gallo},
  booktitle={IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)},
  pages={724--729},
  year={2016},
  organization={IEEE},
  series={INFOCOM-WS 16}

}

@article{nandugudi2016network,
  title={Network function virtualization: through the looking-glass},
  author={A., Nandugudi and M., Gallo and D., Perino and F., Pianese},
  journal={Annals of Telecommunications},
  volume={71},
  number={11},
  pages={573--581},
  year={2016},
  publisher={Springer Paris},
  series={ANN.TELECOM 16}
}

@inproceedings{kirchner2016augustus,
  title={Augustus: a CCN router for programmable networks},
  author={D., Kirchner, and R., Ferdous and R., Lo Cigno and L., Maccari and  L. Linguaglossa and M., Gallo and D., Perino and L., Saino},
  booktitle={Proceedings of the 3rd ACM Conference on Information-Centric Networking},
  pages={31--39},
  year={2016},
  series={ICN 16}
}

@inproceedings{perino2016programmable,
  title={A programmable data plane for heterogeneous NFV platforms},
  author={D., Perino and M., Gallo and R., Laufer and Z., Ben-Houidi and F., Pianese},
  booktitle={2016 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)},
  pages={77--82},
  year={2016},
  organization={IEEE},
  series={INFOCOM-WS 16}
}

@inproceedings{khatouni2016performance,
  title={Performance comparison and optimization of ICN prototypes},
  author={A.S., Khatouni and M., Mellia and L., Venturini and D., Perino and M., Gallo},
  booktitle={2016 IEEE Globecom Workshops (GC Wkshps)},
  pages={1--6},
  year={2016},
  organization={IEEE},
  series={GLOBECOM-WS 16}
}

@inproceedings{duan2017towards,
  title={Towards a Scalable Modular QUIC Server},
  author={Y., Duan and M., Gallo and S., Traverso and R., Laufer and P., Giaccone},
  booktitle={Proceedings of the Workshop on Kernel-Bypass Networks (SIGCOMM Workshop)},
  pages={19--24},
  year={2017},
  series={SIGCOMM-WS 17}
}

@inproceedings{gallo2018climbos,
  title={Climbos: A modular nfv cloud backend for the internet of things},
  author={M., Gallo and S., Ghamri-Doudane and F., Pianese},
  booktitle={2018 9th IFIP International Conference on New Technologies, Mobility and Security (NTMS)},
  pages={1--5},
  year={2018},
  organization={IEEE},
  series={NTMS 18}
}

@inproceedings{gallo2018clicknf,
  title={Clicknf: a modular stack for custom network functions},
  author={M., Gallo and R., Laufer},
  booktitle={2018 USENIX Annual Technical Conference (USENIX ATC 18)},
  pages={745--757},
  year={2018},
  series={ATC 18}
}

@inproceedings{zhang2018high,
  title={High-speed per-flow software monitoring with limited resources},
  author={T., Zhang, and L., Linguaglossa and M., Gallo and P., Giaccone and D., Rossi},
  booktitle={Proceedings of the ACM SIGCOMM 2018 Conference on Posters and Demos},
  pages={138--140},
  year={2018},
  series={SIGCOMM-Poster 18}
}

@inproceedings{gallo2018vns,
  title={vNS: a modular programmable virtual network switch},
  author={M., Gallo and F., Pianese},
  booktitle={Proceedings of the ACM SIGCOMM 2018 Conference on Posters and Demos},
  pages={96--98},
  year={2018},
  series={SIGCOMM-Poster 18}
}

@inproceedings{zhang2018flowmon,
  title={FlowMon-DPDK: Parsimonious per-flow software monitoring at line rate},
  author={T., Zhang and L., Linguaglossa and M., Gallo and P., Giaccone and D., Rossi},
  booktitle={2018 Network Traffic Measurement and Analysis Conference (TMA)},
  pages={1--8},
  year={2018},
  organization={IEEE},
  series={TMA 18}
}

@article{carofiglio2011modeling,
  title={Modeling data transfer in content centric networking (extended version)},
  author={G., Carofiglio and M., Gallo and L., Muscariello and D., Perino},
  journal={Research report},
  year={2011},
  publisher={Tech. Rep.},
  series={Tech. Report 11}
}

@inproceedings{trinelli2019transparent,
  title={Transparent AR processing acceleration at the edge},
  author={M., Trinelli, and M., Gallo and M., Rifai and F., Pianese},
  booktitle={Proceedings of the 2nd International Workshop on Edge Systems, Analytics and Networking},
  pages={30--35},
  year={2019},
  series={EUROSYS-WS 19}
}

@inproceedings{zhang2019benchmarking,
  title={A benchmarking methodology for evaluating software switch performance for nfv},
  author={T., Zhang and L., Linguaglossa and J., Roberts and L., Iannone and M., Gallo and P., Giaccone},
  booktitle={2019 IEEE Conference on Network Softwarization (NetSoft)},
  pages={251--253},
  year={2019},
  organization={IEEE},
  series={Net-Soft 19}

}

@article{zhang2019flowatcher,
  title={FloWatcher-DPDK: lightweight line-rate flow-level monitoring in software},
  author={T., Zhang and L., Linguaglossa and M., Gallo and P., Giaccone and D., Rossi},
  journal={IEEE Transactions on Network and Service Management},
  volume={16},
  number={3},
  pages={1143--1156},
  year={2019},
  publisher={IEEE},
  series={TNSM 19}
}

@inproceedings{zhang2019comparing,
  title={Comparing the performance of state-of-the-art software switches for NFV},
  author={T., Zhang and L., Linguaglossa and M., Gallo and P., Giaccone and L., Iannone and J., Roberts},
  booktitle={In Proc of CoNEXT},
  pages={68--81},
  year={2019},
  series={CoNEXT 19}
}

@inproceedings{muscariellopending,
  title={Pending Interest Table Sizing in Named Data Networking},
  booktitle={In Proc, of ACM ICN},
  author={L., Muscariello and G., Carofiglio and M., Gallo and D., Perino},
  year={2015},
  series={ICN 15}
}

@inproceedings{gallo2020real,
  title={Real-time deep learning based traffic analytics},
  author={M., Gallo and A., Finamore and G., Simon and D., Rossi},
  booktitle={In Proc. of ACM SIGCOMM, Demo session},
  howpublished = {/docs/2020sigcomm.pdf},
  year={2020},
  series={SIGCOMM-Demo 20}
}

@inproceedings{gallo2021fenxi,
  title={FENXI: Fast in-network analytics},
  author={M., Gallo and A., Finamore and G., Simon and D., Rossi},
  booktitle={Proc. IEEE/ACM Symp. Edge Comput.(SEC)},
  howpublished = {/docs/2021sec.pdf},
  pages={1--14},
  abstract = {Live traffic analysis at the first aggregation point in the ISP network enables the implementation of complex traffic engineering policies but is limited by the scarce processing capabilities, especially for Deep Learning (DL) based analytics. The introduction of specialized hardware accelerators i.e., Tensor Processing Unit (TPU), offers the opportunity to enhance processing capabilities of network devices at the edge. Yet, to date, no packet processing pipeline is capable of offering DL-based analysis capabilities in the data-plane, without interfering with network operations. 
  In this paper, we present FENXI, a system to run complex analytics by leveraging TPU. The design of FENXI decouples forwarding operations and traffic analytics which operates at different granularities i.e., packet and flow levels. We conceive two independent modules that asynchronously communicate to exchange network data and analytics results, and design data structures to extract flow level statistics without impacting per-packet processing. We prototyped and evaluated FENXI on general-purpose servers considering both both adversarial and realistic network conditions. Our analysis shows that FENXI can sustains 100 Gbps line rate traffic processing requiring only limited resources, while also dynamically adapting to variable network conditions.},
  year={2021},
  series={SEC 21}
}

@inproceedings{azorin2021DLMeasure,
  author = {Azorin, Rapha\"{e}l and Gallo, Massimo and Finamore, Alessandro and Filippone, Maurizio and Michiardi, Pietro and Rossi, Dario},
  title = {Towards a Generic Deep Learning Pipeline for Traffic Measurements},
  year = {2021},
  abstract = {Traffic measurements are key for network management as testified by the rich literature from both academia and industry. At their foundation, measurements rely on transformation functions f(x) = y, mapping input traffic data x to an output performance metric y. Yet, common practices adopt a bottom-up design (i.e., metric-based) which leads to (i) invest a lot of efforts into (re)discovering how to perform such mapping and (ii) create specialized solutions. For instance, sketches are a compact way to extract traffic properties (heavy-hitters, super-spreaders, etc.) but require analytical modeling to offer correctness guarantees and careful engineering to enable in-device deployment and network-wide measurements.},
  booktitle = {In Proc. of CoNEXT Student Workshop},
  howpublished = {/docs/2021Conext.pdf},
  pages = {5–6},
  series={CoNEXT-SW 21}
}


@inproceedings{finamore2022accelerating,
  title={Accelerating Deep Learning Classification with Error-controlled Approximate-key Caching},
  author={A., Finamore and J., Roberts and M., Gallo and D., Rossi},
  booktitle={In Proc. of IEEE INFOCOM},
  howpublished = {/docs/2022Infocom.pdf},
  abstract={While Deep Learning (DL) technologies are a promising tool to solve networking problems that map to classification tasks, their computational complexity is still too high with respect to real-time traffic measurements requirements. To reduce the DL inference cost, we propose a novel caching paradigm, that we named approximate-key caching, which returns approximate results for lookups of selected input based on cached DL inference results. While approximate cache hits alleviate DL inference workload and increase the system throughput, they however introduce an approximation error. As such, we couple approximate-key caching with an error-correction principled algorithm, that we named auto-refresh.We analytically model our caching system performance for classic LRU and ideal caches, we perform a trace-driven evaluation of the expected performance, and we compare the benefits of our proposed approach with the state-of-the-art similarity caching – this testifies the practical interest of our proposal.},
  year={2022},
  series={INFOCOM 22}
}

@inproceedings{benhouidi2022representation,
  title={Towards a systematic multi-modal representation learning for network data},
  author = {Z., Ben Houidi and R., Azorin and M., Gallo and A., Finamore and D., Rossi},
  booktitle={In Proc. of HotNets},
  howpublished = {/docs/2022HotNets.pdf},
  abstract={Learning the right representations from complex input data is the key ability of successful machine learning (ML) models. The latter are often tailored to a specific data modality. For example, recurrent neural networks (RNNs) were designed having the processing of sequential data in mind, while convolutional neural networks (CNNs) were designed to exploit spatial correlation naturally present in images. Unlike computer vision (CV) and natural language processing (NLP), each of which targets a single well-defined modality, network ML problems often have a mixture of data modalities as input. Yet, instead of exploiting such abundance, prac- titioners tend to rely on sub-features thereof, reducing the problem on single modality for the sake of simplicity.
  In this paper, we advocate for exploiting all the modalities naturally present in network data. As a first step, we observe that network data systematically exhibits a mixture of quantities (e.g., measurements), and entities (e.g., IP addresses, names, etc.). Whereas the former are generally well exploited, the latter are often underused or poorly represented (e.g., with one-hot encoding). We propose to systematically leverage state of the art embedding techniques to learn entity representations, whenever significant sequences of such entities are historically observed. Through two diverse use cases, we show that such entity encoding can benefit and naturally augment classic quantity-based features.},
  year={2022},
  series={HotNets 22}
}

@inproceedings{monterubbiano2022learnedDS,
  title={Learned data structures for per-flow measurements},
  author = {A. Monterubbiano, and R., Azorin and G., Castellano and M., Gallo and S., Pontarelli},
  booktitle={In Proc. of CoNEXT Student Workshop},
  howpublished = {/docs/2022ConextSW.pdf},
  abstract={This work presents a generic framework that exploits learning to improve the quality of network measurements. The main idea is to reuse measures collected by the network monitoring tasks to train an ML model that learns some per-flow characteristics and improves the measurement quality re-configuring the memory according to the learned information. We applied this idea to two different monitoring tasks, we identify the main issues related to this approach and we present some preliminary results.},
  year={2022},
  series={CoNEXT-SW 22}
}

@article{monterubbiano2023SPADA,
  author = {Monterubbiano, Andrea and Azorin, Raphael and Castellano, Gabriele and Gallo, Massimo, and Rossi, Dario and Pontarelli, Salvatore},
  title = {SPADA: A Sparse Approximate Data Structure representation for lightweight per-flow monitoring},
  year = {2023},
  journal = {Proceedings of the ACM on Networking},
  abstract = {Accurate per-flow monitoring is critical for precise network diagnosis, performance analysis, and network operation and management in general. However, the limited amount of memory available on modern programmable devices and the large number of active flows force practitioners to monitor only the most relevant flows with approximate data structures, limiting their view of network traffic. We argue that, due to the skewed nature of network traffic, such data structures are, in practice, heavily underutilized, i.e., sparse, thus wasting a significant amount of memory. This paper proposes a Sparse Approximate Data Structure (SPADA) representation that leverages sparsity to reduce the memory footprint of per-flow monitoring systems in the data plane while preserving their original accuracy. SPADA representation can be integrated into a generic per-flow monitoring system and is suitable for several measurement use cases. We prototype SPADA in P4 for a commercial FPGA target and test our approach with a custom simulator that we make publicly available, on four real network traces over three different monitoring tasks. Our results show that SPADA achieves 2× to 11× memory footprint reduction with respect to the state-of-the-art while maintaining the same accuracy, or even improving it.},
  howpublished = {/docs/2023Conext.pdf},
  topic = {coda},
  series = {CoNEXT 23}
}

@article{azorin2024DUMBO,
  author = {Azorin, Raphael and Monterubbiano, Andrea and  Castellano, Gabriele and Gallo, Massimo, and Rossi, Dario and Pontarelli, Salvatore},
  title = {Taming the Elephants: Affordable Flow Length Prediction in the Data Plane},
  year = {2024},
  journal = {Proceedings of the ACM on Networking},
  abstract = {Machine Learning (ML) shows promising potential for enhancing networking tasks. In particular, early flow size prediction would be beneficial for a wide range of use cases. However, implementing an ML-enabled system is a challenging task due to network devices limited resources. Previous works have demonstrated the feasibility of running simple ML models in the data plane, yet their integration in a practical end-to-end system is not trivial. Additional challenges in resources management and model maintenance need to be addressed to ensure the network task(s) performance improvement justifies the system overhead. In this work, we propose DUMBO, a versatile end-to-end system to generate and exploit flow size hints at line rate.Our system seamlessly integrates and maintains a simple ML model that offers early coarse-grain flow size prediction in the data plane. We evaluate the proposed system on flow scheduling, per-flow packet inter-arrival time distribution, and flow size estimation using real traffic traces, and perform experiments using an FPGA prototype running on an AMD(R)-Xilinx(R) Alveo U280 SmartNIC. Our results show that DUMBO outperforms traditional state-of-the-art approaches by equipping network devices data planes with a lightweight ML model.},
  howpublished = {/docs/2024Conext.pdf},
  series = {CoNEXT 24}
}

@inproceedings{wangchao2023DA4TC,
  author = {Wang, Chao and Finamore, Alessandro and Michiardi, Pietro and Gallo, Massimo and Rossi, Dario},
  title = {Toward Generative Data Augmentation for Traffic Classification},
  year = {2023},
  abstract = {Data Augmentation (DA)--augmenting training data with synthetic samples--is wildly adopted in Computer Vision (CV) to improve models performance. Conversely, DA has not been yet popularized in networking use cases, including Traffic Classification (TC). In this work, we present a preliminary study of 14 hand-crafted DAs applied on the MIRAGE19 dataset. Our results (i) show that DA can reap benefits previously unexplored in TC and (ii) foster a research agenda on the use of generative models to automate DA design.},
  booktitle = {In Proc. of CoNEXT Student Workshop},
  howpublished = {/docs/2023ConextSW.pdf},
  series = {CoNEXT-SW 23}
}

@inproceedings{wangchao2024PAM,
  author={Wang, Chao and Finamore, Alessandro and Michiardi, Pietro and Gallo, Massimo and Rossi, Dario}, 
  title={Data Augmentation for Traffic Classification},
  year={2024},
  abstract="Data Augmentation (DA)---enriching training data by adding synthetic samples---is a technique widely adopted in Computer Vision (CV) and Natural Language Processing (NLP) tasks to improve models performance. Yet, DA has struggled to gain traction in networking contexts, particularly in Traffic Classification (TC) tasks. In this work, we fulfill this gap by benchmarking 18 augmentation functions applied to 3 TC datasets using packet time series as input representation and considering a variety of training conditions. Our results show that (i) DA can reap benefits previously unexplored, (ii) augmentations acting on time series sequence order and masking are better suited for TC than amplitude augmentations and (iii) basic models latent space analysis can help understanding the positive/negative effects of augmentations on classification performance.",
  booktitle={In Proc. of Passive and Active Measurement},
  howpublished = {/docs/2024PAM.pdf},
  series = {PAM 24}
}

@inproceedings{azorin2024MILETS,
  title={Fine-grained Attention in Hierarchical Transformers for Tabular Time-series}, 
  author={Raphael, Azorin and Zied, Ben Houidi and Massimo, Gallo and Alessandro, Finamore and Pietro, Michiardi},
  year={2024},
  abstract="Tabular data is ubiquitous in many real-life systems. In particular, time-dependent tabular data, where rows are chronologically related, is typically used for recording historical events, e.g., financial transactions, healthcare records, or stock history. Recently, hierarchical variants of the attention mechanism of transformer architectures have been used to model tabular time-series data. At first, rows (or columns) are encoded separately by computing attention between their fields. Subsequently, encoded rows (or columns) are attended to one another to model the entire tabular time-series. While efficient, this approach constrains the attention granularity and limits its ability to learn patterns at the field-level across separate rows, or columns. We take a first step to address this gap by proposing Fieldy, a fine-grained hierarchical model that contextualizes fields at both the row and column levels. We compare our proposal against state of the art models on regression and classification tasks using public tabular time-series datasets. Our results show that combining row-wise and column-wise attention improves performance without increasing model size. Code and data are available at this https URL.",
  booktitle={In KDD Workshop Mining and Learning from Time-Series},
  howpublished = {/docs/2024MileTS.pdf},
  series = {MILETS 24}
}

@inproceedings{azorin2024PracticalDL,
  title={Fine-grained Attention in Hierarchical Transformers for Tabular Time-series}, 
  author={Raphael, Azorin and Massimo, Gallo and Alessandro, Finamore and Pietro, Michiardi and Dario, Rossi},
  year={2023},
  abstract="Tabular data is ubiquitous in many real-life systems. In particular, time-dependent tabular data, where rows are chronologically related, is typically used for recording historical events, e.g., financial transactions, healthcare records, or stock history. Recently, hierarchical variants of the attention mechanism of transformer architectures have been used to model tabular time-series data. At first, rows (or columns) are encoded separately by computing attention between their fields. Subsequently, encoded rows (or columns) are attended to one another to model the entire tabular time-series. While efficient, this approach constrains the attention granularity and limits its ability to learn patterns at the field-level across separate rows, or columns. We take a first step to address this gap by proposing Fieldy, a fine-grained hierarchical model that contextualizes fields at both the row and column levels. We compare our proposal against state of the art models on regression and classification tasks using public tabular time-series datasets. Our results show that combining row-wise and column-wise attention improves performance without increasing model size. Code and data are available at this https URL.",
  booktitle={In AAAI Workshop on Practical Deep Learning in the Wild},
  howpublished = {/docs/2023PracticalDL.pdf},
  series = {PracticalDL 24}
}

@inproceedings{wangchao2025PAM,
  title={Fine-grained Attention in Hierarchical Transformers for Tabular Time-series}, 
  author={Wang, Chao and Franzese, Giulio Finamore, Alessandro and Gallo, Massimo and Michiardi, Pietro},
  year={2025},
  abstract="Diffusion models for Text-to-Image (T2I) conditional generation have recently achieved tremendous success. Yet, aligning these models with user's intentions still involves a laborious trial-and-error process, and this challenging alignment problem has attracted considerable attention from the research community. In this work, instead of relying on fine-grained linguistic analyses of prompts, human annotation, or auxiliary vision-language models, we use Mutual Information (MI) to guide model alignment. In brief, our method uses self-supervised fine-tuning and relies on a point-wise (MI) estimation between prompts and images to create a synthetic fine-tuning set for improving model alignment. Our analysis indicates that our method is superior to the state-of-the-art, yet it only requires the pre-trained denoising network of the T2I model itself to estimate MI, and a simple fine-tuning strategy that improves alignment while maintaining image quality.",
  booktitle={In International Conference on Learning Representations 2025},
  series = {ICLR 25}
}